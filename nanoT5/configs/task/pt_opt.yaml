# @package _global_

precision: 'bf16'

model:
  name: 'google/t5-v1_1-base'
  compile: false
  add_config:
    is_bf16: true

optim:
  batch_size: 144
  total_steps: 65536
  grad_acc: 2

# N-params: 247577856

# Wyniki bez logowania (bs = 144):
# * 1.03 with tf32
# * 0.655 z bf16 hf
# * 0.637 z bf16 local
# * 0.627 with kv instead of k, v
# * 0.602 with alibi
# * 0.595 with alibi and full bf16
# * [TBC] 0.572 z flash attention
# * 0.625 z full bf16 local
# * 0.54 z bs=128 grad_acc=1

logging:
  every_steps: 100
  grad_l2: false
  weights_l2: false

eval:
  every_steps: 500000 # Eval in the end only
  steps: 500

checkpoint:
  every_steps: 500000 # Checkpoint in the end only